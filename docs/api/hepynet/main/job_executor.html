<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>hepynet.main.job_executor API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hepynet.main.job_executor</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import datetime
import logging
import pathlib
import random as python_random
import shutil
import time

import atlas_mpl_style as ampl
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import yaml
from cycler import cycler

import hepynet.common.hepy_type as ht
from hepynet.common import common_utils, config_utils
from hepynet.data_io import feed_box
from hepynet.evaluate import (
    evaluate_utils,
    importance,
    kinematics,
    metrics,
    mva_scores,
    significance,
    train_history,
)
from hepynet.main import job_utils
from hepynet.train import train_utils

logger = logging.getLogger(&#34;hepynet&#34;)


class job_executor(object):
    &#34;&#34;&#34;Core class to execute a pdnn job based on given cfg file.&#34;&#34;&#34;

    def __init__(self, yaml_config_path: ht.pathlike):
        &#34;&#34;&#34;Initialize executor.&#34;&#34;&#34;
        self.job_config = None
        self.get_config(yaml_config_path)
        # Set up global plot style and color cycle
        ampl.use_atlas_style(usetex=False)
        color_cycle = self.job_config.apply.color_cycle
        default_cycler = cycler(color=color_cycle)
        plt.rc(&#34;axes&#34;, prop_cycle=default_cycler)

    def execute_jobs(self, resume: bool = False):
        &#34;&#34;&#34;Execute all planned jobs.

        TODO: This function is no longer needed as tune job has been designed to
        be an independent job type. Consider merge with execute_single_job in
        future.

        &#34;&#34;&#34;
        self.job_config.print()
        self.set_save_dir(resume=resume)
        # Execute single job if parameter scan is not needed
        self.execute_single_job(resume=resume)

    def execute_single_job(self, resume: bool = False):
        &#34;&#34;&#34;Execute single DNN training with given configuration.&#34;&#34;&#34;
        # Prepare
        jc = self.job_config.job
        rc = self.job_config.run
        if jc.job_type == &#34;apply&#34;:
            if rc.load_dir == None:
                rc.load_dir = jc.save_dir

        if jc.fix_rdm_seed:
            self.fix_random_seed()

        # Check best tuned config overwrite
        if self.job_config.config.best_tune_overwrite:
            logger.info(&#34;Overwriting training config with best tuned results&#34;)
            best_hypers_path = (
                pathlib.Path(rc.save_sub_dir) / &#34;best_hypers.yaml&#34;
            )
            if best_hypers_path.is_file():
                with open(best_hypers_path, &#34;r&#34;) as best_hypers_file:
                    best_hypers = yaml.load(
                        best_hypers_file, Loader=yaml.FullLoader
                    )
                    self.job_config.train.update(best_hypers)

        self.set_model()
        self.set_model_input()

        if jc.job_type == &#34;train&#34;:
            self.execute_train_job()
        elif jc.job_type == &#34;tune&#34;:
            self.execute_tune_job(resume=resume)
        elif jc.job_type == &#34;apply&#34;:
            self.execute_apply_job()
        else:
            logger.critical(
                f&#34;job.job_type must be train or apply, {jc.job_type} is not supported&#34;
            )

        # Post procedure
        plt.close(&#34;all&#34;)

    def execute_train_job(self):
        # Save the final job_config
        rc = self.job_config.run
        yaml_path = pathlib.Path(rc.save_sub_dir) / &#34;train_config.yaml&#34;
        with open(yaml_path, &#34;w&#34;) as yaml_file:
            yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)
        # Train
        self.model_wrapper.build()
        self.model_wrapper.train()

    def execute_tune_job(self, resume: bool = False):
        # Save the final job_config
        ic = self.job_config.input
        uc = self.job_config.tune
        rc = self.job_config.run
        yaml_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_config.yaml&#34;
        with open(yaml_path, &#34;w&#34;) as yaml_file:
            yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)

        # Prepare tmp inputs
        feedbox = feed_box.Feedbox(self.job_config.clone())
        ## get input
        input_df = feedbox.get_processed_df(keep_unreset=True)
        cols = ic.selected_features
        ## load and save train/test
        train_index = (
            input_df[&#34;is_train&#34;] == True
        )  # index for train and validation
        x = input_df.loc[train_index, cols].values
        y = input_df.loc[train_index, [&#34;y&#34;]].values
        wt = input_df.loc[train_index, &#34;weight&#34;].values
        val_ids = np.random.choice(
            range(len(wt)),
            int(len(wt) * 1.0 * uc.model.val_split),
            replace=False,
        )
        train_ids = np.setdiff1d(np.array(range(len(wt))), val_ids)
        x_train = x[train_ids]
        y_train = y[train_ids]
        wt_train = wt[train_ids]
        x_val = x[val_ids]
        y_val = y[val_ids]
        wt_val = wt[val_ids]
        ## prepare inputs without resetting physic parameter
        physic_para = ic.reset_feature_name
        cols_unreset = list()
        for col in cols:
            if col == physic_para:
                cols_unreset.append(physic_para + &#34;_unreset&#34;)
            else:
                cols_unreset.append(col)
        x_unreset = input_df.loc[train_index, cols_unreset].values
        x_train_unreset = x_unreset[train_ids]
        x_val_unreset = x_unreset[val_ids]
        ## remove negative weight events
        if ic.rm_negative_weight_events == True:
            wt_train = wt_train.clip(min=0)
        tune_input_dir = pathlib.Path(rc.tune_input_cache)
        np.save(tune_input_dir / &#34;x_train.npy&#34;, x_train)
        np.save(tune_input_dir / &#34;x_train_unreset.npy&#34;, x_train_unreset)
        np.save(tune_input_dir / &#34;y_train.npy&#34;, y_train)
        np.save(tune_input_dir / &#34;wt_train.npy&#34;, wt_train)
        np.save(tune_input_dir / &#34;x_val.npy&#34;, x_val)
        np.save(tune_input_dir / &#34;x_val_unreset.npy&#34;, x_val_unreset)
        np.save(tune_input_dir / &#34;y_val.npy&#34;, y_val)
        np.save(tune_input_dir / &#34;wt_val.npy&#34;, wt_val)
        logger.info(f&#34;Temporary tuning input files saved to: {tune_input_dir}&#34;)

        # Tuning hypers
        analysis = train_utils.ray_tune(
            self.model_wrapper, self.job_config, resume=resume
        )

        # Save results
        best_config = analysis.best_config
        save_path = pathlib.Path(rc.save_sub_dir) / &#34;best_hypers.yaml&#34;
        with open(save_path, &#34;w&#34;) as best_hypers_file:
            yaml.dump(best_config, best_hypers_file, indent=4)
        results = analysis.results
        save_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_results.yaml&#34;
        with open(save_path, &#34;w&#34;) as tune_results_file:
            yaml.dump(results, tune_results_file, indent=4)
        save_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_best_trial.yaml&#34;
        with open(save_path, &#34;w&#34;) as best_trial_file:
            yaml.dump(analysis.best_trial, best_trial_file, indent=4)

        # Remove temporary tuning inputs
        shutil.rmtree(tune_input_dir, ignore_errors=True)
        # Remove temporary tuning logs
        if uc.rm_tmp_log:
            # tmp_log_dir = pathlib.Path(rc.save_sub_dir) / &#34;tmp_log&#34;
            tmp_log_dir = uc.tmp_dir
            shutil.rmtree(tmp_log_dir, ignore_errors=True)

    def execute_apply_job(self):
        # Set aliases
        jc = self.job_config.job
        rc = self.job_config.run
        ic = self.job_config.input
        tc = self.job_config.train
        ac = self.job_config.apply

        # Setup save parameters if reports need to be saved
        rc.save_dir = f&#34;{rc.save_sub_dir}/apply/{jc.job_name}&#34;
        pathlib.Path(rc.save_dir).mkdir(parents=True, exist_ok=True)
        # Save the final job_config
        yaml_path = pathlib.Path(rc.save_dir) / &#34;apply_config.yaml&#34;
        with open(yaml_path, &#34;w&#34;) as yaml_file:
            yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)

        # Load inputs
        df_raw = self.model_wrapper.get_feedbox().get_raw_df()
        if logger.level == logging.DEBUG:
            logger.warn(
                f&#34;Randomly sampling 10000 events as input for debugging purpose.&#34;
            )
            time.sleep(3)
            df_raw = df_raw.sample(n=10000)
            df_raw.reset_index(drop=True, inplace=True)
        df = self.model_wrapper.get_feedbox().get_processed_df(raw_df=df_raw)

        # Studies not depending on models
        ## metrics curves
        if ac.book_history:
            train_history.plot_history(
                self.model_wrapper, self.job_config, save_dir=rc.save_dir
            )
        ## input kinematic plots
        if ac.book_kine:
            logger.info(&#34;Plotting input (raw) distributions.&#34;)
            kinematics.plot_input(
                df_raw,
                self.job_config,
                save_dir=f&#34;{rc.save_dir}/kinematics/raw&#34;,
                is_raw=True,
            )
            logger.info(&#34;Plotting input (processed) distributions.&#34;)
            kinematics.plot_input(
                df,
                self.job_config,
                save_dir=f&#34;{rc.save_dir}/kinematics/processed&#34;,
                is_raw=False,
            )
        ## correlation matrix
        if ac.book_cor_matrix:
            logger.info(&#34;Making correlation matrix&#34;)
            kinematics.plot_correlation_matrix(
                df_raw, self.job_config, save_dir=f&#34;{rc.save_dir}/kinematics&#34;
            )

        # Studies depending on models
        if ac.jump_model_studies:
            logger.info(&#34;Ignoring model dependent studies as specified&#34;)
            return

        ## generate fit arrays
        if ac.book_fit_inputs:
            save_region = ac.fit_df.region
            if save_region is None:
                save_region = ic.region
            logger.info(&#34;Dumping numpy arrays for fitting.&#34;)
            evaluate_utils.dump_fit_df(
                self.model_wrapper,
                df_raw,
                df,
                self.job_config,
                save_dir=ac.fit_df.save_dir,
            )

        ## loop over models at different epochs
        epoch_checklist = [None]
        if ac.check_model_epoch:
            for epoch_id in range(tc.epochs):
                epoch = epoch_id + 1
                if epoch % ac.epoch_check_interval == 1:
                    epoch_checklist.append(epoch)
        for epoch in epoch_checklist:
            logger.info(&#34;&gt;&#34; * 80)
            if epoch is None:
                logger.info(f&#34;Checking model(s) at final epoch&#34;)
                epoch_str = &#34;final&#34;
            else:
                logger.info(f&#34;Checking model(s) at epoch {epoch}&#34;)
                epoch_str = str(epoch)
            self.model_wrapper.load_model(epoch=epoch)

            # create epoch sub-directory
            epoch_subdir = evaluate_utils.create_epoch_subdir(
                rc.save_dir, epoch, len(str(tc.epochs))
            )
            if epoch_subdir is None:
                logger.error(
                    f&#34;Can&#39;t create epoch subdir, skip evaluation at epoch {epoch_str}!&#34;
                )
                return

            # update y values predictions
            y_pred, _, _ = evaluate_utils.k_folds_predict(
                self.model_wrapper.get_model(), df[ic.selected_features].values
            )
            df.loc[:, &#34;y_pred&#34;] = y_pred

            # metrics (PR, ROC, confusion matrix)
            if ac.book_confusion_matrix or ac.book_roc or ac.book_pr:
                metrics.make_metrics_plot(
                    df_raw, df, self.job_config, epoch_subdir
                )
            # overtrain check
            if ac.book_train_test_compare:
                mva_scores.plot_train_test_compare(
                    df, self.job_config, epoch_subdir
                )
            # data/mc scores comparison
            if ac.book_mva_scores_data_mc:
                mva_scores.plot_mva_scores(
                    df_raw, df, self.job_config, epoch_subdir,
                )
            # Make significance scan plot
            if ac.book_significance_scan:
                significance.plot_significance_scan(
                    df, self.job_config, epoch_subdir
                )
            # kinematics with DNN cuts
            if ac.book_cut_kine_study:
                for dnn_cut in ac.cfg_cut_kine_study.dnn_cut_list:
                    dnn_kine_path = (
                        epoch_subdir / f&#34;kine_cut_dnn_p{dnn_cut * 100}&#34;
                    )
                    dnn_kine_path.mkdir(parents=True, exist_ok=True)
                    kinematics.plot_input_dnn(
                        df_raw,
                        df,
                        self.job_config,
                        dnn_cut=dnn_cut,
                        save_dir=dnn_kine_path,
                    )
            # feature permuted importance
            if ac.book_importance_study:
                logger.info(&#34;Checking input feature importance&#34;)
                importance.plot_feature_importance(
                    self.model_wrapper, df, self.job_config, epoch_subdir
                )

            logger.info(&#34;&lt;&#34; * 80)

        return

    def fix_random_seed(self):
        &#34;&#34;&#34;Fixes random seed

        Ref:
            https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development

        Note:
            The seed setting funcions called in this function shouldn&#39;t be set 
            again in later code, otherwise extra randomness will be introduced 
            (even if set same seed). The reason is unknown yet.

        &#34;&#34;&#34;
        seed = self.job_config.job.rdm_seed
        # The below is necessary for starting Numpy generated random numbers
        # in a well-defined initial state.
        np.random.seed(seed)
        # The below is necessary for starting core Python generated random numbers
        # in a well-defined state.
        python_random.seed(seed)
        # The below set_seed() will make random number generation
        # in the TensorFlow backend have a well-defined initial state.
        # For further details, see:
        # https://www.tensorflow.org/api_docs/python/tf/random/set_seed
        tf.random.set_seed(seed)

    def get_config(self, yaml_path: ht.pathlike):
        &#34;&#34;&#34;Retrieves configurations from yaml file.&#34;&#34;&#34;
        cfg_path = job_utils.get_valid_cfg_path(yaml_path)
        if not pathlib.Path(cfg_path).is_file():
            logger.error(&#34;No vallid configuration file path provided.&#34;)
            raise FileNotFoundError
        yaml_dict = config_utils.load_yaml_dict(cfg_path)
        job_config_temp = config_utils.Hepy_Config(yaml_dict)
        # Check whether need to import other (default) ini file first
        if hasattr(job_config_temp, &#34;config&#34;):
            import_ini_path_list = job_config_temp.config.include
            if import_ini_path_list:
                for cfg_path in import_ini_path_list:
                    self.get_config(cfg_path)
                    logger.info(f&#34;Included config: {cfg_path}&#34;)
        if self.job_config:
            self.job_config.update(yaml_dict)
        else:
            self.job_config = job_config_temp

        jc = self.job_config.job
        ic = self.job_config.input
        rc = self.job_config.run
        if jc.date_str is None:
            rc.datestr = datetime.date.today().strftime(&#34;%Y-%m-%d&#34;)
        else:
            rc.datestr = jc.date_str
        if ic.selected_features:
            rc.input_dim = len(ic.selected_features)
        rc.config_collected = True

    def set_model(self):
        logger.info(&#34;Setting up model&#34;)
        tc = self.job_config.train
        jc = self.job_config.job
        model_class = train_utils.get_model_class(tc.model_class)
        self.model_wrapper = model_class(self.job_config)
        # Load model for &#34;apply&#34; job
        if jc.job_type == &#34;apply&#34;:
            self.model_wrapper.load_model()

    def set_model_input(self):
        logger.info(&#34;Processing inputs&#34;)
        self.model_wrapper.set_inputs(self.job_config)

    def set_save_dir(self, resume: bool = False):
        &#34;&#34;&#34;Sets the directory to save the outputs&#34;&#34;&#34;
        jc = self.job_config.job
        rc = self.job_config.run

        # Determine sub-directory for result saving
        create_new = True
        job_dir_name = jc.job_name
        if jc.job_type == &#34;tune&#34;:
            if resume:
                create_new = False
        elif jc.job_type == &#34;train&#34;:
            if jc.tune_job_name != &#34;TUNE_JOB_NAME_DEF&#34;:
                create_new = False
                job_dir_name = jc.tune_job_name
        elif jc.job_type == &#34;apply&#34;:
            create_new = False
            if jc.tune_job_name != &#34;TUNE_JOB_NAME_DEF&#34;:
                job_dir_name = jc.tune_job_name
            elif jc.train_job_name != &#34;TRAIN_JOB_NAME_DEF&#34;:
                job_dir_name = jc.train_job_name
            else:
                logger.critical(
                    f&#34;Job type is apply but neither tune_job_name nor train_job_name specified! Please update the config.&#34;
                )
                exit()
        else:
            logger.critical(f&#34;Unknown job_type {jc.job_type}!&#34;)
            exit()

        if create_new:
            dir_pattern = f&#34;{jc.save_dir}/{rc.datestr}_{job_dir_name}_v{{}}&#34;
            output_match = common_utils.get_newest_file_version(dir_pattern)
            rc.save_sub_dir = output_match[&#34;path&#34;]
        else:
            if jc.fix_date_str:
                dir_pattern = (
                    f&#34;{jc.save_dir}/{rc.datestr}_{job_dir_name}_v{{}}&#34;
                )
            else:
                dir_pattern = f&#34;{jc.save_dir}/*_{job_dir_name}_v{{}}&#34;
            output_match = common_utils.get_newest_file_version(
                dir_pattern, use_existing=True
            )
            if output_match:
                rc.save_sub_dir = output_match[&#34;path&#34;]
            else:
                logger.error(
                    f&#34;Can&#39;t find existing work folder matched pattern {dir_pattern}, please check the settings.&#34;
                )
                exit()
        logger.info(f&#34;Setup work directory: {rc.save_sub_dir}&#34;)
        pathlib.Path(rc.save_sub_dir).mkdir(parents=True, exist_ok=True)

        # Set input cache for tune job
        if jc.job_type == &#34;tune&#34;:
            tune_input_cache = pathlib.Path(rc.save_sub_dir) / &#34;tmp&#34;
            tune_input_cache.mkdir(parents=True, exist_ok=True)
            rc.tune_input_cache = str(tune_input_cache)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="hepynet.main.job_executor.job_executor"><code class="flex name class">
<span>class <span class="ident">job_executor</span></span>
<span>(</span><span>yaml_config_path: Union[str, os.PathLike])</span>
</code></dt>
<dd>
<div class="desc"><p>Core class to execute a pdnn job based on given cfg file.</p>
<p>Initialize executor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class job_executor(object):
    &#34;&#34;&#34;Core class to execute a pdnn job based on given cfg file.&#34;&#34;&#34;

    def __init__(self, yaml_config_path: ht.pathlike):
        &#34;&#34;&#34;Initialize executor.&#34;&#34;&#34;
        self.job_config = None
        self.get_config(yaml_config_path)
        # Set up global plot style and color cycle
        ampl.use_atlas_style(usetex=False)
        color_cycle = self.job_config.apply.color_cycle
        default_cycler = cycler(color=color_cycle)
        plt.rc(&#34;axes&#34;, prop_cycle=default_cycler)

    def execute_jobs(self, resume: bool = False):
        &#34;&#34;&#34;Execute all planned jobs.

        TODO: This function is no longer needed as tune job has been designed to
        be an independent job type. Consider merge with execute_single_job in
        future.

        &#34;&#34;&#34;
        self.job_config.print()
        self.set_save_dir(resume=resume)
        # Execute single job if parameter scan is not needed
        self.execute_single_job(resume=resume)

    def execute_single_job(self, resume: bool = False):
        &#34;&#34;&#34;Execute single DNN training with given configuration.&#34;&#34;&#34;
        # Prepare
        jc = self.job_config.job
        rc = self.job_config.run
        if jc.job_type == &#34;apply&#34;:
            if rc.load_dir == None:
                rc.load_dir = jc.save_dir

        if jc.fix_rdm_seed:
            self.fix_random_seed()

        # Check best tuned config overwrite
        if self.job_config.config.best_tune_overwrite:
            logger.info(&#34;Overwriting training config with best tuned results&#34;)
            best_hypers_path = (
                pathlib.Path(rc.save_sub_dir) / &#34;best_hypers.yaml&#34;
            )
            if best_hypers_path.is_file():
                with open(best_hypers_path, &#34;r&#34;) as best_hypers_file:
                    best_hypers = yaml.load(
                        best_hypers_file, Loader=yaml.FullLoader
                    )
                    self.job_config.train.update(best_hypers)

        self.set_model()
        self.set_model_input()

        if jc.job_type == &#34;train&#34;:
            self.execute_train_job()
        elif jc.job_type == &#34;tune&#34;:
            self.execute_tune_job(resume=resume)
        elif jc.job_type == &#34;apply&#34;:
            self.execute_apply_job()
        else:
            logger.critical(
                f&#34;job.job_type must be train or apply, {jc.job_type} is not supported&#34;
            )

        # Post procedure
        plt.close(&#34;all&#34;)

    def execute_train_job(self):
        # Save the final job_config
        rc = self.job_config.run
        yaml_path = pathlib.Path(rc.save_sub_dir) / &#34;train_config.yaml&#34;
        with open(yaml_path, &#34;w&#34;) as yaml_file:
            yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)
        # Train
        self.model_wrapper.build()
        self.model_wrapper.train()

    def execute_tune_job(self, resume: bool = False):
        # Save the final job_config
        ic = self.job_config.input
        uc = self.job_config.tune
        rc = self.job_config.run
        yaml_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_config.yaml&#34;
        with open(yaml_path, &#34;w&#34;) as yaml_file:
            yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)

        # Prepare tmp inputs
        feedbox = feed_box.Feedbox(self.job_config.clone())
        ## get input
        input_df = feedbox.get_processed_df(keep_unreset=True)
        cols = ic.selected_features
        ## load and save train/test
        train_index = (
            input_df[&#34;is_train&#34;] == True
        )  # index for train and validation
        x = input_df.loc[train_index, cols].values
        y = input_df.loc[train_index, [&#34;y&#34;]].values
        wt = input_df.loc[train_index, &#34;weight&#34;].values
        val_ids = np.random.choice(
            range(len(wt)),
            int(len(wt) * 1.0 * uc.model.val_split),
            replace=False,
        )
        train_ids = np.setdiff1d(np.array(range(len(wt))), val_ids)
        x_train = x[train_ids]
        y_train = y[train_ids]
        wt_train = wt[train_ids]
        x_val = x[val_ids]
        y_val = y[val_ids]
        wt_val = wt[val_ids]
        ## prepare inputs without resetting physic parameter
        physic_para = ic.reset_feature_name
        cols_unreset = list()
        for col in cols:
            if col == physic_para:
                cols_unreset.append(physic_para + &#34;_unreset&#34;)
            else:
                cols_unreset.append(col)
        x_unreset = input_df.loc[train_index, cols_unreset].values
        x_train_unreset = x_unreset[train_ids]
        x_val_unreset = x_unreset[val_ids]
        ## remove negative weight events
        if ic.rm_negative_weight_events == True:
            wt_train = wt_train.clip(min=0)
        tune_input_dir = pathlib.Path(rc.tune_input_cache)
        np.save(tune_input_dir / &#34;x_train.npy&#34;, x_train)
        np.save(tune_input_dir / &#34;x_train_unreset.npy&#34;, x_train_unreset)
        np.save(tune_input_dir / &#34;y_train.npy&#34;, y_train)
        np.save(tune_input_dir / &#34;wt_train.npy&#34;, wt_train)
        np.save(tune_input_dir / &#34;x_val.npy&#34;, x_val)
        np.save(tune_input_dir / &#34;x_val_unreset.npy&#34;, x_val_unreset)
        np.save(tune_input_dir / &#34;y_val.npy&#34;, y_val)
        np.save(tune_input_dir / &#34;wt_val.npy&#34;, wt_val)
        logger.info(f&#34;Temporary tuning input files saved to: {tune_input_dir}&#34;)

        # Tuning hypers
        analysis = train_utils.ray_tune(
            self.model_wrapper, self.job_config, resume=resume
        )

        # Save results
        best_config = analysis.best_config
        save_path = pathlib.Path(rc.save_sub_dir) / &#34;best_hypers.yaml&#34;
        with open(save_path, &#34;w&#34;) as best_hypers_file:
            yaml.dump(best_config, best_hypers_file, indent=4)
        results = analysis.results
        save_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_results.yaml&#34;
        with open(save_path, &#34;w&#34;) as tune_results_file:
            yaml.dump(results, tune_results_file, indent=4)
        save_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_best_trial.yaml&#34;
        with open(save_path, &#34;w&#34;) as best_trial_file:
            yaml.dump(analysis.best_trial, best_trial_file, indent=4)

        # Remove temporary tuning inputs
        shutil.rmtree(tune_input_dir, ignore_errors=True)
        # Remove temporary tuning logs
        if uc.rm_tmp_log:
            # tmp_log_dir = pathlib.Path(rc.save_sub_dir) / &#34;tmp_log&#34;
            tmp_log_dir = uc.tmp_dir
            shutil.rmtree(tmp_log_dir, ignore_errors=True)

    def execute_apply_job(self):
        # Set aliases
        jc = self.job_config.job
        rc = self.job_config.run
        ic = self.job_config.input
        tc = self.job_config.train
        ac = self.job_config.apply

        # Setup save parameters if reports need to be saved
        rc.save_dir = f&#34;{rc.save_sub_dir}/apply/{jc.job_name}&#34;
        pathlib.Path(rc.save_dir).mkdir(parents=True, exist_ok=True)
        # Save the final job_config
        yaml_path = pathlib.Path(rc.save_dir) / &#34;apply_config.yaml&#34;
        with open(yaml_path, &#34;w&#34;) as yaml_file:
            yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)

        # Load inputs
        df_raw = self.model_wrapper.get_feedbox().get_raw_df()
        if logger.level == logging.DEBUG:
            logger.warn(
                f&#34;Randomly sampling 10000 events as input for debugging purpose.&#34;
            )
            time.sleep(3)
            df_raw = df_raw.sample(n=10000)
            df_raw.reset_index(drop=True, inplace=True)
        df = self.model_wrapper.get_feedbox().get_processed_df(raw_df=df_raw)

        # Studies not depending on models
        ## metrics curves
        if ac.book_history:
            train_history.plot_history(
                self.model_wrapper, self.job_config, save_dir=rc.save_dir
            )
        ## input kinematic plots
        if ac.book_kine:
            logger.info(&#34;Plotting input (raw) distributions.&#34;)
            kinematics.plot_input(
                df_raw,
                self.job_config,
                save_dir=f&#34;{rc.save_dir}/kinematics/raw&#34;,
                is_raw=True,
            )
            logger.info(&#34;Plotting input (processed) distributions.&#34;)
            kinematics.plot_input(
                df,
                self.job_config,
                save_dir=f&#34;{rc.save_dir}/kinematics/processed&#34;,
                is_raw=False,
            )
        ## correlation matrix
        if ac.book_cor_matrix:
            logger.info(&#34;Making correlation matrix&#34;)
            kinematics.plot_correlation_matrix(
                df_raw, self.job_config, save_dir=f&#34;{rc.save_dir}/kinematics&#34;
            )

        # Studies depending on models
        if ac.jump_model_studies:
            logger.info(&#34;Ignoring model dependent studies as specified&#34;)
            return

        ## generate fit arrays
        if ac.book_fit_inputs:
            save_region = ac.fit_df.region
            if save_region is None:
                save_region = ic.region
            logger.info(&#34;Dumping numpy arrays for fitting.&#34;)
            evaluate_utils.dump_fit_df(
                self.model_wrapper,
                df_raw,
                df,
                self.job_config,
                save_dir=ac.fit_df.save_dir,
            )

        ## loop over models at different epochs
        epoch_checklist = [None]
        if ac.check_model_epoch:
            for epoch_id in range(tc.epochs):
                epoch = epoch_id + 1
                if epoch % ac.epoch_check_interval == 1:
                    epoch_checklist.append(epoch)
        for epoch in epoch_checklist:
            logger.info(&#34;&gt;&#34; * 80)
            if epoch is None:
                logger.info(f&#34;Checking model(s) at final epoch&#34;)
                epoch_str = &#34;final&#34;
            else:
                logger.info(f&#34;Checking model(s) at epoch {epoch}&#34;)
                epoch_str = str(epoch)
            self.model_wrapper.load_model(epoch=epoch)

            # create epoch sub-directory
            epoch_subdir = evaluate_utils.create_epoch_subdir(
                rc.save_dir, epoch, len(str(tc.epochs))
            )
            if epoch_subdir is None:
                logger.error(
                    f&#34;Can&#39;t create epoch subdir, skip evaluation at epoch {epoch_str}!&#34;
                )
                return

            # update y values predictions
            y_pred, _, _ = evaluate_utils.k_folds_predict(
                self.model_wrapper.get_model(), df[ic.selected_features].values
            )
            df.loc[:, &#34;y_pred&#34;] = y_pred

            # metrics (PR, ROC, confusion matrix)
            if ac.book_confusion_matrix or ac.book_roc or ac.book_pr:
                metrics.make_metrics_plot(
                    df_raw, df, self.job_config, epoch_subdir
                )
            # overtrain check
            if ac.book_train_test_compare:
                mva_scores.plot_train_test_compare(
                    df, self.job_config, epoch_subdir
                )
            # data/mc scores comparison
            if ac.book_mva_scores_data_mc:
                mva_scores.plot_mva_scores(
                    df_raw, df, self.job_config, epoch_subdir,
                )
            # Make significance scan plot
            if ac.book_significance_scan:
                significance.plot_significance_scan(
                    df, self.job_config, epoch_subdir
                )
            # kinematics with DNN cuts
            if ac.book_cut_kine_study:
                for dnn_cut in ac.cfg_cut_kine_study.dnn_cut_list:
                    dnn_kine_path = (
                        epoch_subdir / f&#34;kine_cut_dnn_p{dnn_cut * 100}&#34;
                    )
                    dnn_kine_path.mkdir(parents=True, exist_ok=True)
                    kinematics.plot_input_dnn(
                        df_raw,
                        df,
                        self.job_config,
                        dnn_cut=dnn_cut,
                        save_dir=dnn_kine_path,
                    )
            # feature permuted importance
            if ac.book_importance_study:
                logger.info(&#34;Checking input feature importance&#34;)
                importance.plot_feature_importance(
                    self.model_wrapper, df, self.job_config, epoch_subdir
                )

            logger.info(&#34;&lt;&#34; * 80)

        return

    def fix_random_seed(self):
        &#34;&#34;&#34;Fixes random seed

        Ref:
            https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development

        Note:
            The seed setting funcions called in this function shouldn&#39;t be set 
            again in later code, otherwise extra randomness will be introduced 
            (even if set same seed). The reason is unknown yet.

        &#34;&#34;&#34;
        seed = self.job_config.job.rdm_seed
        # The below is necessary for starting Numpy generated random numbers
        # in a well-defined initial state.
        np.random.seed(seed)
        # The below is necessary for starting core Python generated random numbers
        # in a well-defined state.
        python_random.seed(seed)
        # The below set_seed() will make random number generation
        # in the TensorFlow backend have a well-defined initial state.
        # For further details, see:
        # https://www.tensorflow.org/api_docs/python/tf/random/set_seed
        tf.random.set_seed(seed)

    def get_config(self, yaml_path: ht.pathlike):
        &#34;&#34;&#34;Retrieves configurations from yaml file.&#34;&#34;&#34;
        cfg_path = job_utils.get_valid_cfg_path(yaml_path)
        if not pathlib.Path(cfg_path).is_file():
            logger.error(&#34;No vallid configuration file path provided.&#34;)
            raise FileNotFoundError
        yaml_dict = config_utils.load_yaml_dict(cfg_path)
        job_config_temp = config_utils.Hepy_Config(yaml_dict)
        # Check whether need to import other (default) ini file first
        if hasattr(job_config_temp, &#34;config&#34;):
            import_ini_path_list = job_config_temp.config.include
            if import_ini_path_list:
                for cfg_path in import_ini_path_list:
                    self.get_config(cfg_path)
                    logger.info(f&#34;Included config: {cfg_path}&#34;)
        if self.job_config:
            self.job_config.update(yaml_dict)
        else:
            self.job_config = job_config_temp

        jc = self.job_config.job
        ic = self.job_config.input
        rc = self.job_config.run
        if jc.date_str is None:
            rc.datestr = datetime.date.today().strftime(&#34;%Y-%m-%d&#34;)
        else:
            rc.datestr = jc.date_str
        if ic.selected_features:
            rc.input_dim = len(ic.selected_features)
        rc.config_collected = True

    def set_model(self):
        logger.info(&#34;Setting up model&#34;)
        tc = self.job_config.train
        jc = self.job_config.job
        model_class = train_utils.get_model_class(tc.model_class)
        self.model_wrapper = model_class(self.job_config)
        # Load model for &#34;apply&#34; job
        if jc.job_type == &#34;apply&#34;:
            self.model_wrapper.load_model()

    def set_model_input(self):
        logger.info(&#34;Processing inputs&#34;)
        self.model_wrapper.set_inputs(self.job_config)

    def set_save_dir(self, resume: bool = False):
        &#34;&#34;&#34;Sets the directory to save the outputs&#34;&#34;&#34;
        jc = self.job_config.job
        rc = self.job_config.run

        # Determine sub-directory for result saving
        create_new = True
        job_dir_name = jc.job_name
        if jc.job_type == &#34;tune&#34;:
            if resume:
                create_new = False
        elif jc.job_type == &#34;train&#34;:
            if jc.tune_job_name != &#34;TUNE_JOB_NAME_DEF&#34;:
                create_new = False
                job_dir_name = jc.tune_job_name
        elif jc.job_type == &#34;apply&#34;:
            create_new = False
            if jc.tune_job_name != &#34;TUNE_JOB_NAME_DEF&#34;:
                job_dir_name = jc.tune_job_name
            elif jc.train_job_name != &#34;TRAIN_JOB_NAME_DEF&#34;:
                job_dir_name = jc.train_job_name
            else:
                logger.critical(
                    f&#34;Job type is apply but neither tune_job_name nor train_job_name specified! Please update the config.&#34;
                )
                exit()
        else:
            logger.critical(f&#34;Unknown job_type {jc.job_type}!&#34;)
            exit()

        if create_new:
            dir_pattern = f&#34;{jc.save_dir}/{rc.datestr}_{job_dir_name}_v{{}}&#34;
            output_match = common_utils.get_newest_file_version(dir_pattern)
            rc.save_sub_dir = output_match[&#34;path&#34;]
        else:
            if jc.fix_date_str:
                dir_pattern = (
                    f&#34;{jc.save_dir}/{rc.datestr}_{job_dir_name}_v{{}}&#34;
                )
            else:
                dir_pattern = f&#34;{jc.save_dir}/*_{job_dir_name}_v{{}}&#34;
            output_match = common_utils.get_newest_file_version(
                dir_pattern, use_existing=True
            )
            if output_match:
                rc.save_sub_dir = output_match[&#34;path&#34;]
            else:
                logger.error(
                    f&#34;Can&#39;t find existing work folder matched pattern {dir_pattern}, please check the settings.&#34;
                )
                exit()
        logger.info(f&#34;Setup work directory: {rc.save_sub_dir}&#34;)
        pathlib.Path(rc.save_sub_dir).mkdir(parents=True, exist_ok=True)

        # Set input cache for tune job
        if jc.job_type == &#34;tune&#34;:
            tune_input_cache = pathlib.Path(rc.save_sub_dir) / &#34;tmp&#34;
            tune_input_cache.mkdir(parents=True, exist_ok=True)
            rc.tune_input_cache = str(tune_input_cache)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="hepynet.main.job_executor.job_executor.execute_apply_job"><code class="name flex">
<span>def <span class="ident">execute_apply_job</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_apply_job(self):
    # Set aliases
    jc = self.job_config.job
    rc = self.job_config.run
    ic = self.job_config.input
    tc = self.job_config.train
    ac = self.job_config.apply

    # Setup save parameters if reports need to be saved
    rc.save_dir = f&#34;{rc.save_sub_dir}/apply/{jc.job_name}&#34;
    pathlib.Path(rc.save_dir).mkdir(parents=True, exist_ok=True)
    # Save the final job_config
    yaml_path = pathlib.Path(rc.save_dir) / &#34;apply_config.yaml&#34;
    with open(yaml_path, &#34;w&#34;) as yaml_file:
        yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)

    # Load inputs
    df_raw = self.model_wrapper.get_feedbox().get_raw_df()
    if logger.level == logging.DEBUG:
        logger.warn(
            f&#34;Randomly sampling 10000 events as input for debugging purpose.&#34;
        )
        time.sleep(3)
        df_raw = df_raw.sample(n=10000)
        df_raw.reset_index(drop=True, inplace=True)
    df = self.model_wrapper.get_feedbox().get_processed_df(raw_df=df_raw)

    # Studies not depending on models
    ## metrics curves
    if ac.book_history:
        train_history.plot_history(
            self.model_wrapper, self.job_config, save_dir=rc.save_dir
        )
    ## input kinematic plots
    if ac.book_kine:
        logger.info(&#34;Plotting input (raw) distributions.&#34;)
        kinematics.plot_input(
            df_raw,
            self.job_config,
            save_dir=f&#34;{rc.save_dir}/kinematics/raw&#34;,
            is_raw=True,
        )
        logger.info(&#34;Plotting input (processed) distributions.&#34;)
        kinematics.plot_input(
            df,
            self.job_config,
            save_dir=f&#34;{rc.save_dir}/kinematics/processed&#34;,
            is_raw=False,
        )
    ## correlation matrix
    if ac.book_cor_matrix:
        logger.info(&#34;Making correlation matrix&#34;)
        kinematics.plot_correlation_matrix(
            df_raw, self.job_config, save_dir=f&#34;{rc.save_dir}/kinematics&#34;
        )

    # Studies depending on models
    if ac.jump_model_studies:
        logger.info(&#34;Ignoring model dependent studies as specified&#34;)
        return

    ## generate fit arrays
    if ac.book_fit_inputs:
        save_region = ac.fit_df.region
        if save_region is None:
            save_region = ic.region
        logger.info(&#34;Dumping numpy arrays for fitting.&#34;)
        evaluate_utils.dump_fit_df(
            self.model_wrapper,
            df_raw,
            df,
            self.job_config,
            save_dir=ac.fit_df.save_dir,
        )

    ## loop over models at different epochs
    epoch_checklist = [None]
    if ac.check_model_epoch:
        for epoch_id in range(tc.epochs):
            epoch = epoch_id + 1
            if epoch % ac.epoch_check_interval == 1:
                epoch_checklist.append(epoch)
    for epoch in epoch_checklist:
        logger.info(&#34;&gt;&#34; * 80)
        if epoch is None:
            logger.info(f&#34;Checking model(s) at final epoch&#34;)
            epoch_str = &#34;final&#34;
        else:
            logger.info(f&#34;Checking model(s) at epoch {epoch}&#34;)
            epoch_str = str(epoch)
        self.model_wrapper.load_model(epoch=epoch)

        # create epoch sub-directory
        epoch_subdir = evaluate_utils.create_epoch_subdir(
            rc.save_dir, epoch, len(str(tc.epochs))
        )
        if epoch_subdir is None:
            logger.error(
                f&#34;Can&#39;t create epoch subdir, skip evaluation at epoch {epoch_str}!&#34;
            )
            return

        # update y values predictions
        y_pred, _, _ = evaluate_utils.k_folds_predict(
            self.model_wrapper.get_model(), df[ic.selected_features].values
        )
        df.loc[:, &#34;y_pred&#34;] = y_pred

        # metrics (PR, ROC, confusion matrix)
        if ac.book_confusion_matrix or ac.book_roc or ac.book_pr:
            metrics.make_metrics_plot(
                df_raw, df, self.job_config, epoch_subdir
            )
        # overtrain check
        if ac.book_train_test_compare:
            mva_scores.plot_train_test_compare(
                df, self.job_config, epoch_subdir
            )
        # data/mc scores comparison
        if ac.book_mva_scores_data_mc:
            mva_scores.plot_mva_scores(
                df_raw, df, self.job_config, epoch_subdir,
            )
        # Make significance scan plot
        if ac.book_significance_scan:
            significance.plot_significance_scan(
                df, self.job_config, epoch_subdir
            )
        # kinematics with DNN cuts
        if ac.book_cut_kine_study:
            for dnn_cut in ac.cfg_cut_kine_study.dnn_cut_list:
                dnn_kine_path = (
                    epoch_subdir / f&#34;kine_cut_dnn_p{dnn_cut * 100}&#34;
                )
                dnn_kine_path.mkdir(parents=True, exist_ok=True)
                kinematics.plot_input_dnn(
                    df_raw,
                    df,
                    self.job_config,
                    dnn_cut=dnn_cut,
                    save_dir=dnn_kine_path,
                )
        # feature permuted importance
        if ac.book_importance_study:
            logger.info(&#34;Checking input feature importance&#34;)
            importance.plot_feature_importance(
                self.model_wrapper, df, self.job_config, epoch_subdir
            )

        logger.info(&#34;&lt;&#34; * 80)

    return</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.execute_jobs"><code class="name flex">
<span>def <span class="ident">execute_jobs</span></span>(<span>self, resume: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute all planned jobs.</p>
<p>TODO: This function is no longer needed as tune job has been designed to
be an independent job type. Consider merge with execute_single_job in
future.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_jobs(self, resume: bool = False):
    &#34;&#34;&#34;Execute all planned jobs.

    TODO: This function is no longer needed as tune job has been designed to
    be an independent job type. Consider merge with execute_single_job in
    future.

    &#34;&#34;&#34;
    self.job_config.print()
    self.set_save_dir(resume=resume)
    # Execute single job if parameter scan is not needed
    self.execute_single_job(resume=resume)</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.execute_single_job"><code class="name flex">
<span>def <span class="ident">execute_single_job</span></span>(<span>self, resume: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute single DNN training with given configuration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_single_job(self, resume: bool = False):
    &#34;&#34;&#34;Execute single DNN training with given configuration.&#34;&#34;&#34;
    # Prepare
    jc = self.job_config.job
    rc = self.job_config.run
    if jc.job_type == &#34;apply&#34;:
        if rc.load_dir == None:
            rc.load_dir = jc.save_dir

    if jc.fix_rdm_seed:
        self.fix_random_seed()

    # Check best tuned config overwrite
    if self.job_config.config.best_tune_overwrite:
        logger.info(&#34;Overwriting training config with best tuned results&#34;)
        best_hypers_path = (
            pathlib.Path(rc.save_sub_dir) / &#34;best_hypers.yaml&#34;
        )
        if best_hypers_path.is_file():
            with open(best_hypers_path, &#34;r&#34;) as best_hypers_file:
                best_hypers = yaml.load(
                    best_hypers_file, Loader=yaml.FullLoader
                )
                self.job_config.train.update(best_hypers)

    self.set_model()
    self.set_model_input()

    if jc.job_type == &#34;train&#34;:
        self.execute_train_job()
    elif jc.job_type == &#34;tune&#34;:
        self.execute_tune_job(resume=resume)
    elif jc.job_type == &#34;apply&#34;:
        self.execute_apply_job()
    else:
        logger.critical(
            f&#34;job.job_type must be train or apply, {jc.job_type} is not supported&#34;
        )

    # Post procedure
    plt.close(&#34;all&#34;)</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.execute_train_job"><code class="name flex">
<span>def <span class="ident">execute_train_job</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_train_job(self):
    # Save the final job_config
    rc = self.job_config.run
    yaml_path = pathlib.Path(rc.save_sub_dir) / &#34;train_config.yaml&#34;
    with open(yaml_path, &#34;w&#34;) as yaml_file:
        yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)
    # Train
    self.model_wrapper.build()
    self.model_wrapper.train()</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.execute_tune_job"><code class="name flex">
<span>def <span class="ident">execute_tune_job</span></span>(<span>self, resume: bool = False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_tune_job(self, resume: bool = False):
    # Save the final job_config
    ic = self.job_config.input
    uc = self.job_config.tune
    rc = self.job_config.run
    yaml_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_config.yaml&#34;
    with open(yaml_path, &#34;w&#34;) as yaml_file:
        yaml.dump(self.job_config.get_config_dict(), yaml_file, indent=4)

    # Prepare tmp inputs
    feedbox = feed_box.Feedbox(self.job_config.clone())
    ## get input
    input_df = feedbox.get_processed_df(keep_unreset=True)
    cols = ic.selected_features
    ## load and save train/test
    train_index = (
        input_df[&#34;is_train&#34;] == True
    )  # index for train and validation
    x = input_df.loc[train_index, cols].values
    y = input_df.loc[train_index, [&#34;y&#34;]].values
    wt = input_df.loc[train_index, &#34;weight&#34;].values
    val_ids = np.random.choice(
        range(len(wt)),
        int(len(wt) * 1.0 * uc.model.val_split),
        replace=False,
    )
    train_ids = np.setdiff1d(np.array(range(len(wt))), val_ids)
    x_train = x[train_ids]
    y_train = y[train_ids]
    wt_train = wt[train_ids]
    x_val = x[val_ids]
    y_val = y[val_ids]
    wt_val = wt[val_ids]
    ## prepare inputs without resetting physic parameter
    physic_para = ic.reset_feature_name
    cols_unreset = list()
    for col in cols:
        if col == physic_para:
            cols_unreset.append(physic_para + &#34;_unreset&#34;)
        else:
            cols_unreset.append(col)
    x_unreset = input_df.loc[train_index, cols_unreset].values
    x_train_unreset = x_unreset[train_ids]
    x_val_unreset = x_unreset[val_ids]
    ## remove negative weight events
    if ic.rm_negative_weight_events == True:
        wt_train = wt_train.clip(min=0)
    tune_input_dir = pathlib.Path(rc.tune_input_cache)
    np.save(tune_input_dir / &#34;x_train.npy&#34;, x_train)
    np.save(tune_input_dir / &#34;x_train_unreset.npy&#34;, x_train_unreset)
    np.save(tune_input_dir / &#34;y_train.npy&#34;, y_train)
    np.save(tune_input_dir / &#34;wt_train.npy&#34;, wt_train)
    np.save(tune_input_dir / &#34;x_val.npy&#34;, x_val)
    np.save(tune_input_dir / &#34;x_val_unreset.npy&#34;, x_val_unreset)
    np.save(tune_input_dir / &#34;y_val.npy&#34;, y_val)
    np.save(tune_input_dir / &#34;wt_val.npy&#34;, wt_val)
    logger.info(f&#34;Temporary tuning input files saved to: {tune_input_dir}&#34;)

    # Tuning hypers
    analysis = train_utils.ray_tune(
        self.model_wrapper, self.job_config, resume=resume
    )

    # Save results
    best_config = analysis.best_config
    save_path = pathlib.Path(rc.save_sub_dir) / &#34;best_hypers.yaml&#34;
    with open(save_path, &#34;w&#34;) as best_hypers_file:
        yaml.dump(best_config, best_hypers_file, indent=4)
    results = analysis.results
    save_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_results.yaml&#34;
    with open(save_path, &#34;w&#34;) as tune_results_file:
        yaml.dump(results, tune_results_file, indent=4)
    save_path = pathlib.Path(rc.save_sub_dir) / &#34;tune_best_trial.yaml&#34;
    with open(save_path, &#34;w&#34;) as best_trial_file:
        yaml.dump(analysis.best_trial, best_trial_file, indent=4)

    # Remove temporary tuning inputs
    shutil.rmtree(tune_input_dir, ignore_errors=True)
    # Remove temporary tuning logs
    if uc.rm_tmp_log:
        # tmp_log_dir = pathlib.Path(rc.save_sub_dir) / &#34;tmp_log&#34;
        tmp_log_dir = uc.tmp_dir
        shutil.rmtree(tmp_log_dir, ignore_errors=True)</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.fix_random_seed"><code class="name flex">
<span>def <span class="ident">fix_random_seed</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Fixes random seed</p>
<h2 id="ref">Ref</h2>
<p><a href="https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development">https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development</a></p>
<h2 id="note">Note</h2>
<p>The seed setting funcions called in this function shouldn't be set
again in later code, otherwise extra randomness will be introduced
(even if set same seed). The reason is unknown yet.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fix_random_seed(self):
    &#34;&#34;&#34;Fixes random seed

    Ref:
        https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development

    Note:
        The seed setting funcions called in this function shouldn&#39;t be set 
        again in later code, otherwise extra randomness will be introduced 
        (even if set same seed). The reason is unknown yet.

    &#34;&#34;&#34;
    seed = self.job_config.job.rdm_seed
    # The below is necessary for starting Numpy generated random numbers
    # in a well-defined initial state.
    np.random.seed(seed)
    # The below is necessary for starting core Python generated random numbers
    # in a well-defined state.
    python_random.seed(seed)
    # The below set_seed() will make random number generation
    # in the TensorFlow backend have a well-defined initial state.
    # For further details, see:
    # https://www.tensorflow.org/api_docs/python/tf/random/set_seed
    tf.random.set_seed(seed)</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self, yaml_path: Union[str, os.PathLike])</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves configurations from yaml file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self, yaml_path: ht.pathlike):
    &#34;&#34;&#34;Retrieves configurations from yaml file.&#34;&#34;&#34;
    cfg_path = job_utils.get_valid_cfg_path(yaml_path)
    if not pathlib.Path(cfg_path).is_file():
        logger.error(&#34;No vallid configuration file path provided.&#34;)
        raise FileNotFoundError
    yaml_dict = config_utils.load_yaml_dict(cfg_path)
    job_config_temp = config_utils.Hepy_Config(yaml_dict)
    # Check whether need to import other (default) ini file first
    if hasattr(job_config_temp, &#34;config&#34;):
        import_ini_path_list = job_config_temp.config.include
        if import_ini_path_list:
            for cfg_path in import_ini_path_list:
                self.get_config(cfg_path)
                logger.info(f&#34;Included config: {cfg_path}&#34;)
    if self.job_config:
        self.job_config.update(yaml_dict)
    else:
        self.job_config = job_config_temp

    jc = self.job_config.job
    ic = self.job_config.input
    rc = self.job_config.run
    if jc.date_str is None:
        rc.datestr = datetime.date.today().strftime(&#34;%Y-%m-%d&#34;)
    else:
        rc.datestr = jc.date_str
    if ic.selected_features:
        rc.input_dim = len(ic.selected_features)
    rc.config_collected = True</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.set_model"><code class="name flex">
<span>def <span class="ident">set_model</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_model(self):
    logger.info(&#34;Setting up model&#34;)
    tc = self.job_config.train
    jc = self.job_config.job
    model_class = train_utils.get_model_class(tc.model_class)
    self.model_wrapper = model_class(self.job_config)
    # Load model for &#34;apply&#34; job
    if jc.job_type == &#34;apply&#34;:
        self.model_wrapper.load_model()</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.set_model_input"><code class="name flex">
<span>def <span class="ident">set_model_input</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_model_input(self):
    logger.info(&#34;Processing inputs&#34;)
    self.model_wrapper.set_inputs(self.job_config)</code></pre>
</details>
</dd>
<dt id="hepynet.main.job_executor.job_executor.set_save_dir"><code class="name flex">
<span>def <span class="ident">set_save_dir</span></span>(<span>self, resume: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the directory to save the outputs</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_save_dir(self, resume: bool = False):
    &#34;&#34;&#34;Sets the directory to save the outputs&#34;&#34;&#34;
    jc = self.job_config.job
    rc = self.job_config.run

    # Determine sub-directory for result saving
    create_new = True
    job_dir_name = jc.job_name
    if jc.job_type == &#34;tune&#34;:
        if resume:
            create_new = False
    elif jc.job_type == &#34;train&#34;:
        if jc.tune_job_name != &#34;TUNE_JOB_NAME_DEF&#34;:
            create_new = False
            job_dir_name = jc.tune_job_name
    elif jc.job_type == &#34;apply&#34;:
        create_new = False
        if jc.tune_job_name != &#34;TUNE_JOB_NAME_DEF&#34;:
            job_dir_name = jc.tune_job_name
        elif jc.train_job_name != &#34;TRAIN_JOB_NAME_DEF&#34;:
            job_dir_name = jc.train_job_name
        else:
            logger.critical(
                f&#34;Job type is apply but neither tune_job_name nor train_job_name specified! Please update the config.&#34;
            )
            exit()
    else:
        logger.critical(f&#34;Unknown job_type {jc.job_type}!&#34;)
        exit()

    if create_new:
        dir_pattern = f&#34;{jc.save_dir}/{rc.datestr}_{job_dir_name}_v{{}}&#34;
        output_match = common_utils.get_newest_file_version(dir_pattern)
        rc.save_sub_dir = output_match[&#34;path&#34;]
    else:
        if jc.fix_date_str:
            dir_pattern = (
                f&#34;{jc.save_dir}/{rc.datestr}_{job_dir_name}_v{{}}&#34;
            )
        else:
            dir_pattern = f&#34;{jc.save_dir}/*_{job_dir_name}_v{{}}&#34;
        output_match = common_utils.get_newest_file_version(
            dir_pattern, use_existing=True
        )
        if output_match:
            rc.save_sub_dir = output_match[&#34;path&#34;]
        else:
            logger.error(
                f&#34;Can&#39;t find existing work folder matched pattern {dir_pattern}, please check the settings.&#34;
            )
            exit()
    logger.info(f&#34;Setup work directory: {rc.save_sub_dir}&#34;)
    pathlib.Path(rc.save_sub_dir).mkdir(parents=True, exist_ok=True)

    # Set input cache for tune job
    if jc.job_type == &#34;tune&#34;:
        tune_input_cache = pathlib.Path(rc.save_sub_dir) / &#34;tmp&#34;
        tune_input_cache.mkdir(parents=True, exist_ok=True)
        rc.tune_input_cache = str(tune_input_cache)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="hepynet.main" href="index.html">hepynet.main</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="hepynet.main.job_executor.job_executor" href="#hepynet.main.job_executor.job_executor">job_executor</a></code></h4>
<ul class="two-column">
<li><code><a title="hepynet.main.job_executor.job_executor.execute_apply_job" href="#hepynet.main.job_executor.job_executor.execute_apply_job">execute_apply_job</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.execute_jobs" href="#hepynet.main.job_executor.job_executor.execute_jobs">execute_jobs</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.execute_single_job" href="#hepynet.main.job_executor.job_executor.execute_single_job">execute_single_job</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.execute_train_job" href="#hepynet.main.job_executor.job_executor.execute_train_job">execute_train_job</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.execute_tune_job" href="#hepynet.main.job_executor.job_executor.execute_tune_job">execute_tune_job</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.fix_random_seed" href="#hepynet.main.job_executor.job_executor.fix_random_seed">fix_random_seed</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.get_config" href="#hepynet.main.job_executor.job_executor.get_config">get_config</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.set_model" href="#hepynet.main.job_executor.job_executor.set_model">set_model</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.set_model_input" href="#hepynet.main.job_executor.job_executor.set_model_input">set_model_input</a></code></li>
<li><code><a title="hepynet.main.job_executor.job_executor.set_save_dir" href="#hepynet.main.job_executor.job_executor.set_save_dir">set_save_dir</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>