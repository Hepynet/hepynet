{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning with different size of signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # add self-defined module in the parent path\n",
    "sys.path.append(\"../..\") # add self-defined module in the parent path\n",
    "\n",
    "from array import array\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate, SimpleRNN, GRU, Masking, Lambda, Reshape, Dropout, RNN\n",
    "from keras.optimizers import Adagrad, SGD, RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Dropout, LeakyReLU, LSTM, Conv1D, SimpleRNN, Concatenate\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lfv_pdnn_code_v1.train.train_utils import *\n",
    "from lfv_pdnn_code_v1.common.common_utils import *\n",
    "\n",
    "selected_features = [0, 1, 2, 3, 5, 6, 7, 13, 14, 15, 16, 17, 18, 19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load background samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load background array\n",
    "xb1 = np.load('/mnt/e/data/lfv/ntuples_last_run/TestData/data_npy/tree_bkg1.npy')\n",
    "xb2 = np.load('/mnt/e/data/lfv/ntuples_last_run/TestData/data_npy/tree_bkg2.npy')\n",
    "xb3 = np.load('/mnt/e/data/lfv/ntuples_last_run/TestData/data_npy/tree_bkg3.npy')\n",
    "xb4 = np.load('/mnt/e/data/lfv/ntuples_last_run/TestData/data_npy/tree_bkg4.npy')\n",
    "xb5 = np.load('/mnt/e/data/lfv/ntuples_last_run/TestData/data_npy/tree_bkg5.npy')\n",
    "xb = np.concatenate((xb1, xb2, xb3, xb4, xb5))\n",
    "\n",
    "data_path = \"/mnt/e/data/new_ntuple/mc16a\"\n",
    "# load di_boson\n",
    "directory = data_path + \"/di_boson\"\n",
    "search_pattern = \"*.npy\"\n",
    "absolute_file_list, file_name_list = get_file_list(directory, search_pattern)\n",
    "xb_di_boson = np.array([])\n",
    "for path in absolute_file_list:\n",
    "    temp_array = np.load(path)\n",
    "    if len(temp_array) == 0:\n",
    "        continue\n",
    "    if len(xb_di_boson) == 0:\n",
    "        xb_di_boson = temp_array.copy()\n",
    "    else:\n",
    "        xb_di_boson = np.concatenate((xb_di_boson, temp_array))\n",
    "print \"xb_di_boson shape:\", xb_di_boson.shape\n",
    "\n",
    "# load top_quark\n",
    "directory = data_path + \"/top_quark\"\n",
    "search_pattern = \"*.npy\"\n",
    "absolute_file_list, file_name_list = get_file_list(directory, search_pattern)\n",
    "xb_top_quark = np.array([])\n",
    "for path in absolute_file_list:\n",
    "    temp_array = np.load(path)\n",
    "    if len(temp_array) == 0:\n",
    "        continue\n",
    "    if len(xb_top_quark) == 0:\n",
    "        xb_top_quark = temp_array.copy()\n",
    "    else:\n",
    "        xb_top_quark = np.concatenate((xb_top_quark, temp_array))\n",
    "print \"xb_top_quark shape:\", xb_top_quark.shape\n",
    "\n",
    "# load w_jets\n",
    "directory = data_path + \"/w_jets\"\n",
    "search_pattern = \"*.npy\"\n",
    "absolute_file_list, file_name_list = get_file_list(directory, search_pattern)\n",
    "xb_w_jets = np.array([])\n",
    "for path in absolute_file_list:\n",
    "    temp_array = np.load(path)\n",
    "    if len(temp_array) == 0:\n",
    "        continue\n",
    "    if len(xb_w_jets) == 0:\n",
    "        xb_w_jets = temp_array.copy()\n",
    "    else:\n",
    "        xb_w_jets = np.concatenate((xb_w_jets, temp_array))\n",
    "print \"xb_w_jets shape:\", xb_w_jets.shape\n",
    "\n",
    "# load z_ll\n",
    "directory = data_path + \"/z_ll\"\n",
    "search_pattern = \"*.npy\"\n",
    "absolute_file_list, file_name_list = get_file_list(directory, search_pattern)\n",
    "xb_z_ll = np.array([])\n",
    "for path in absolute_file_list:\n",
    "    temp_array = np.load(path)\n",
    "    if len(temp_array) == 0:\n",
    "        continue\n",
    "    if len(xb_z_ll) == 0:\n",
    "        xb_z_ll = temp_array.copy()\n",
    "    else:\n",
    "        xb_z_ll = np.concatenate((xb_z_ll, temp_array))\n",
    "print \"xb_z_ll shape:\", xb_z_ll.shape\n",
    "\n",
    "# Add all background together\n",
    "xb = np.concatenate((xb_di_boson, xb_top_quark, xb_w_jets, xb_z_ll))\n",
    "print \"xb shape:\", xb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Load selected signal samples\n",
    "according to the previous results, use mass range (500 - 2400 GeV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_min = 5000\n",
    "mass_max = 0\n",
    "xs_studied = np.array([])\n",
    "mass_scan_map = [5, 20]\n",
    "data_path = \"/mnt/e/data/new_ntuple/mc16a\"\n",
    "for i, mass in enumerate(mass_scan_map):\n",
    "    # load signal\n",
    "    xs_add = np.load(data_path + \"/signal/emu/rpv_emu_{}00GeV.npy\".format(mass))\n",
    "    xs_temp = np.load(data_path + \"/signal/etau/rpv_etau_{}00GeV.npy\".format(mass))\n",
    "    xs_add = np.concatenate((xs_add, xs_temp))\n",
    "    xs_temp = np.load(data_path + \"/signal/mutau/rpv_mutau_{}00GeV.npy\".format(mass))\n",
    "    xs_add = np.concatenate((xs_add, xs_temp))\n",
    "    if len(xs_studied) == 0:\n",
    "        xs_studied = xs_add.copy()\n",
    "    else:\n",
    "        xs_studied = np.concatenate((xs_studied, xs_add))\n",
    "    xs_emu = modify_array(xs_add, weight_id = -1, \n",
    "                          select_channel = True, channel_id = -4,\n",
    "                          norm = True, shuffle = True, shuffle_seed = 485)\n",
    "    mass_sigma = get_mass_range(xs_emu[:, 0], xs_emu[:, -1])\n",
    "    mass_min_temp = mass * 100 - mass_sigma\n",
    "    mass_max_temp = mass * 100 + mass_sigma\n",
    "    if mass_min_temp < mass_min:\n",
    "        mass_min = mass_min_temp\n",
    "    if mass_max_temp > mass_max:\n",
    "        mass_max = mass_max_temp\n",
    "        \n",
    "# select emu channel and shuffle\n",
    "xs_emu = modify_array(xs_studied, weight_id = -1, \n",
    "                      select_channel = True, channel_id = -4,\n",
    "                      norm = True, shuffle = True)\n",
    "\n",
    "# get bkg in range\n",
    "xb_emu = modify_array(xb, weight_id = -1, remove_negative_weight = True, select_channel = True, channel_id = -4,\n",
    "                      select_mass = True, mass_id = 0, mass_min = mass_min, mass_max = mass_max,\n",
    "                      reset_mass = True, reset_mass_array = xs_emu, reset_mass_id = 0,\n",
    "                      norm = True, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - kinematic plots for emu channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MakePlots(xs_emu, xb_emu, 0, bins = 50, range = (0, 3000)  , density = True,\n",
    "          xlabel = \"di-Lepton mass / GeV\", ylabel = \"events\", show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 1, bins = 50, range = (0, 1000)  , density = True,\n",
    "          xlabel=\"Ele_pt / GeV\"          , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 2, bins = 50, range = (-3, 3)    , density = True,\n",
    "          xlabel=\"Ele_eta\"               , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 3, bins = 50, range = (-3.2, 3.2), density = True,\n",
    "          xlabel=\"Ele_phi\"               , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 5, bins = 50, range = (0, 5000)  , density = True,\n",
    "          xlabel=\"Mu_pt / GeV\"           , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 6, bins = 50, range = (-3, 3)    , density = True,\n",
    "          xlabel=\"Mu_eta\"                , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 7, bins = 50, range = (-3.2, 3.2), density = True,\n",
    "          xlabel=\"Mu_phi\"                , ylabel=\"Events\"  , show_plot = True)\n",
    "\n",
    "MakePlots(xs_emu, xb_emu, 13, bins = 50, range = (0, 3000)  , density = True,\n",
    "          xlabel=\"MET_et\"                , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 14, bins = 50, range = (-3.2, 3.2), density = True,\n",
    "          xlabel=\"MET_phi\"               , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 15, bins = 50, range = (0, 1000)  , density = True,\n",
    "          xlabel=\"di-Lepton_pt\"          , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 16, bins = 50, range = (-3, 3)    , density = True,\n",
    "          xlabel=\"di-Lepton_eta\"         , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 17, bins = 50, range = (-3.2, 3.2), density = True,\n",
    "          xlabel=\"di-Lepton_phi\"         , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 18, bins = 50, range = (-3.2, 3.2), density = True,\n",
    "          xlabel=\"di-Lepton_Dphi\"        , ylabel=\"Events\"  , show_plot = True)\n",
    "MakePlots(xs_emu, xb_emu, 18, bins = 50, range = (0, 5)     , density = True,\n",
    "          xlabel=\"di-Lepton_DR\"          , ylabel=\"Events\"  , show_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - use 100% -> 1% signal for training\n",
    "number of background events fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage_list = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "percentage_list = [1]\n",
    "#percentage_list = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 1]\n",
    "#percentage_list = [0.01, 0.1, 0.2, 0.5, 1]\n",
    "\n",
    "# training with different percentage of signals\n",
    "for percent in percentage_list:\n",
    "    # set up training model\n",
    "    node_num = 300\n",
    "    model_deep = Sequential()\n",
    "    model_deep.add(Dense(node_num, kernel_initializer='uniform', input_dim = len(selected_features)))\n",
    "    model_deep.add(BatchNormalization())\n",
    "    model_deep.add(Dense(node_num, kernel_initializer=\"glorot_normal\", activation=\"relu\"))\n",
    "    model_deep.add(BatchNormalization())\n",
    "    model_deep.add(Dense(node_num, kernel_initializer=\"glorot_normal\", activation=\"relu\"))\n",
    "    model_deep.add(BatchNormalization())\n",
    "    model_deep.add(Dense(node_num, kernel_initializer=\"glorot_normal\", activation=\"relu\"))\n",
    "    model_deep.add(BatchNormalization())\n",
    "    model_deep.add(Dense(node_num, kernel_initializer=\"glorot_normal\", activation=\"relu\"))\n",
    "    model_deep.add(BatchNormalization())\n",
    "    model_deep.add(Dense(node_num, kernel_initializer=\"glorot_normal\", activation=\"relu\"))\n",
    "    model_deep.add(BatchNormalization())\n",
    "    model_deep.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n",
    "    # set loss, optimizer and evaluation metrics\n",
    "    model_deep.compile(loss=\"binary_crossentropy\", optimizer=SGD(lr=0.025, decay=1e-6), metrics=[\"accuracy\"])\n",
    "\n",
    "    # get part of signal events\n",
    "    print \"*\" * 80\n",
    "    print \"use {}% signal for training\".format(percent * 100)\n",
    "    print \"sig events quantity:\", len(xs_emu) * percent\n",
    "    print \"bkg events quantity:\", len(xb_emu)\n",
    "    index_len = int(len(xs_emu) * percent)\n",
    "    index = np.random.choice(xs_emu.shape[0], index_len, replace = False)\n",
    "    xs_emu_part = xs_emu[index]\n",
    "    #print \"debug:\", xs_emu_part[0:5]\n",
    "    print \"debug:\", index[0:10]\n",
    "    print \"debug: \", xs_emu.shape[0], xs_emu_part.shape[0], index_len\n",
    "    \"\"\"\n",
    "    xs_emu_part, x2, y1, y2 = train_test_split(xs_emu, np.ones(len(xs_emu)), \n",
    "                                               test_size= 1 - percent, \n",
    "                                               random_state=3456, shuffle=True)\n",
    "    \"\"\"\n",
    "    xs_emu_part = modify_array(xs_emu_part, weight_id = -1, \n",
    "                               norm = True, shuffle = True)\n",
    "    xb_emu_temp = modify_array(xb_emu, weight_id = -1, mass_id = 0,\n",
    "                               reset_mass = True, reset_mass_array = xs_emu_part, reset_mass_id = 0,\n",
    "                               norm = True, shuffle = True)\n",
    "    \n",
    "    # get training data\n",
    "    x_emu_train, x_emu_test, y_emu_train, y_emu_test, xs_emu_test, xb_emu_test = \\\n",
    "    split_and_combine(xs_emu_part, xb_emu_temp, shuffle_before_return = True)\n",
    "    # get test data\n",
    "    #x1, x_emu_test, y1, y_emu_test, xs_emu_test, xb_emu_test = \\\n",
    "    #split_and_combine(xs_emu_part, xb_emu, shuffle_before_return = True)\n",
    "\n",
    "    # select features wanted\n",
    "    x_emu_train_selected = get_part_feature(x_emu_train, selected_features)\n",
    "    x_emu_test_selected = get_part_feature(x_emu_test, selected_features)\n",
    "    print \"train data shape:\", x_emu_train_selected.shape\n",
    "    print \"test data shape:\", x_emu_test_selected.shape \n",
    "\n",
    "    # train the model\n",
    "    train_history = model_deep.fit(x_emu_train_selected, y_emu_train, batch_size = 100, epochs = 30,\n",
    "                    validation_split = 0.25 , sample_weight = x_emu_train[:, -1], verbose = 1)\n",
    "    score = model_deep.evaluate(x_emu_test_selected, y_emu_test, verbose=0, sample_weight = x_emu_test[:, -1])\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # load test (cross validation) data\n",
    "    xs_emu_test_selected = get_part_feature(xs_emu, selected_features) # use full sample for validation\n",
    "    xb_emu_test_selected = get_part_feature(xb_emu, selected_features) #\n",
    "    \n",
    "    # display scores\n",
    "    plt.hist(xs_emu[:, 0], bins = 100, weights = xs_emu[:, -1], range = (0, 10000), histtype='step', label='signal', density=True)\n",
    "    plt.xlabel(\"mass\")\n",
    "    plt.ylabel(\"events\")\n",
    "    plt.show()\n",
    "    PlotScores(xs_emu_test_selected, xb_emu_test_selected, model_deep, bins = 100, range = (0, 1), density = True)\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train_history.history['acc'])\n",
    "    plt.plot(train_history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.ylim((0, 1))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper center')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper center')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # make roc plots for signal\n",
    "    print \"roc for sig and bkg\"\n",
    "    plt.ylabel('tpr')\n",
    "    plt.xlabel('fpr')\n",
    "    predictions_dm = model_deep.predict(get_part_feature(x_emu_train, selected_features))\n",
    "    fpr_dm, tpr_dm, threshold = roc_curve(y_emu_train, predictions_dm)\n",
    "    plt.plot(fpr_dm, tpr_dm)\n",
    "    predictions_dm = model_deep.predict(get_part_feature(x_emu_test, selected_features))\n",
    "    fpr_dm_test, tpr_dm_test, threshold_test = roc_curve(y_emu_test, predictions_dm)\n",
    "    plt.plot(fpr_dm_test, tpr_dm_test)\n",
    "    plt.legend(['train', 'test'], loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print \"auc for train:\", auc(fpr_dm, tpr_dm)\n",
    "    print \"auc for test: \", auc(fpr_dm_test, tpr_dm_test)\n",
    "    \n",
    "    # clear model for next training\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
